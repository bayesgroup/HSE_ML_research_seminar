
Вопрос 1
Какое априорное распределение у переменной z в работе Bayesian Compression for Deep Learning? Какое приближенное вариационное распределение используется для этой переменной? Какие трюки предлагают авторы для снижения дисперсии при приближении функции потерь?
Вопрос 2
Как выбор параметризации вариационного распределения позволяет добиться групповой разреженности сети в работе Bayesian Compression for Deep Learning?
Вопрос 3
По каким параметрам авторы EfficientNet предлагают масштабировать сеть? Как асимптотически себя ведут затраты по памяти при обучении и количество весов в модели при масштабировании этих параметров?
Вопрос 4
Как авторы Large Scale Memory with Product Keys предлагают использовать слой с внешней памятью в архитектуре трансформера?
Вопрос 5
Что такое locality-sensitive hashing? Запишите формулу схемы хеширования, используемую в статье Reformer: The Efficient Transformer, поясните обозначения.
Вопрос 6
Какую репараметризацию для параметров масштабирования сети предлагают авторы EfficientNet? Как число операций с плавающей точкой зависит от введенного параметра \phi (compound scale coefficient)?