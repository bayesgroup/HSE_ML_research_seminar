
Вопрос 1
Какую репараметризацию для параметров масштабирования сети предлагают авторы EfficientNet? Как число операций с плавающей точкой зависит от введенного параметра \phi (compound scale coefficient)?
Вопрос 2
Опишите алгоритм вычисления внимания в статье Reformer: The Efficient Transformer. За счет чего авторам удается повысить эффективность алгоритма?
Вопрос 3
Как использование декартового произведения ключей позволяет ускорить поиск ближайших соседей? Какая сложность поиска в эффективном алгоритме и классическом? Почему?
Вопрос 4
Как выбор параметризации вариационного распределения позволяет добиться групповой разреженности сети в работе Bayesian Compression for Deep Learning?
Вопрос 5
Зачем нужны обратимые слои в работе Reformer: The Efficient Transformer? Запишите формулу прямого и обратного прохода по ним.
Вопрос 6
Как авторы Large Scale Memory with Product Keys предлагают использовать слой с внешней памятью в архитектуре трансформера?