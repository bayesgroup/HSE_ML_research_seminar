Морозов Никита, рецензия
Your classifier is secretly an energy based model and you should treat it like one

1. Содержание и вклад 

В статье предлагается подход, в котором стандартный нейросетевой классификатор изображений p(y|x) интерпретируется и обучается как energy based модель для распределения p(x, y). Модель авторов превосходит предыдущие state-of-the-art гибридные модели для классификации и генерации, а также достигает качества классификации и генерации, адекватного в сравнении с state-of-the-art моделями для отдельных задач. Авторы показывают, что обученная таким образом energy based модель дает нам классификатор, который лучше откалиброван и более устойчив к adversarial атакам в сравнении с классификатором, который можно получить путем стандартной процедуры обучения той же нейросети. Также полученная модель может быть использована в задаче out-of-distribution detection и показывает на ней хорошие результаты.

В более ранних работах уже исследовалась возможность моделирования распределения p(x, y) для изображений с помощью energy based моделей, однако из них нельзя было напрямую извлечь классификатор p(y|x), как это можно сделать в предложенном подходе. Вклад авторов состоит в том, что они новым способом ввели energy based модель для p(x, y), а также провели немало экспериментов, показывающих, что данный подход позволяет получить лучшее качество, а также обладает рядом других важных достоинств.

2. Сильные стороны

По моему мнению, статья вносит значимый вклад в область возможных применений energy based моделей, показывая, как стандартный нейросетевой классификатор может извлечь большую выгоду из дополнительного введения energy based модели над логитами на выходе.

Для потверждения этой выгоды, был проведен обширный эмпирический анализ. Авторы проводят большой ряд экспериментов, постановка и результаты каждого из которых хорошо описаны в работе. Результаты показывают, что данный подход может иметь широкое практическое применение. Особенно впечатлает, что точность классификации довольно слабо падает, в сравнении со стандартной процедрой обучения той же самой сети.

Приведено полное и понятное описание предложенного подхода, а также дополнительные рассуждения и интуиция, которые привели авторов к нему.

3. Слабые стороны

Утверждения о том, что представленная модель может тягаться со state-of-the art подходами для классификации или генерации не очень обоснованы. В качестве бейзлайна для многих экспериментов авторы берут WideResNet, представленный еще в 2016 году. Если смотреть результаты 2018-2019 годов (сама статья была впервые опубликована в 2019 году) на https://paperswithcode.com/sota, видим accuracy в ~98% на CIFAR10 и ~89% на CIFAR100 для подходов, не использующих дополнительные данные, в сравнение с 92.9% и 72.9% у авторов. GAN модели тех времен на CIFAR10 досигали ~15 FID при сходном IS, в сравнение с 38.4 у авторов.

Авторы отмечают нестабильность процедуры обучения как наиболее важную из возникших проблем. При этом уделяют ей всего один абзац в конце аппендикса и дают очень краткое и поверхностное описание конкретных ситуаций, в которых процедура обучения расходится, а также способов, которые они применяли для борьбы с ними. В этом месте они ссылаются на другую статью, однако она также дает довольно мало ответов. Все это усложняет воспроизводимость результатов статьи и, что наиболее важно, возможное практическое применение предложенного подхода. 

Также в псевдокоде процедуры обучения имеется ошибка: у слагаемых в оценке градиента логарифма правдоподобия перепутаны знаки.

Авторы отмечают, что убрали батч нормализацию из используемой архитектуры "to remove sources of stochasticity in early experiments". Все итоговые результаты они приводят для нейросети без батч нормализации, однако отмечают, что им также удавалось успешно учить сеть с батч нормализацией и другими методами стохастической регуляризации, такими как дропаут. Мне не очень понятен выбор авторов для итоговой версии статьи оставить сеть без батч нормализации (которая, как я предполагаю, могла бы улучшить стабильность процедуры обучения).

4. Качество текста

Статья написана очень понятным языком и хорошо структурирована, ее легко и приятно читать.

5. Воспроизводимость

Подробное описание модели и экспериментов, а также гитхаб репозиторий, на котором все это выложено, сильно облегчает воспроизводимость статьи. Однако все еще остаются вопросы к плохо описанным проблемам с нестабильностью процедуры обучения.

6. Дополнительные комментарии, предложения по улучшению

Как я уже отмечал, данной статье сильно помогло бы расшриение раздела о проблемах с нестабильностьюю процедуры обучения. Также, по моему мнению, больший акцент на возможностях практического применения предложенного подхода помог бы сделать статью привлекательнее для более широкой публики, незнакомой с energy based моделями.


Оценка: 8/10
Уверенность: 5/5