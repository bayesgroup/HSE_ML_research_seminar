{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U57Hx7J0CgFq"
   },
   "source": [
    "# Эксперимент 1\n",
    "\n",
    "Хотим выучить трансформер на классификацию с CLS токена посередине внутри сильной модели с полным количеством слоев.\n",
    "\n",
    "Данные отсюда: https://www.kaggle.com/c/nlp-2021-hw1/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK354UuREcNo"
   },
   "outputs": [],
   "source": [
    "! pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohoSNHCwCkf-"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from warnings import filterwarnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer,get_linear_schedule_with_warmup\n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfJw7SZ4DN5x"
   },
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aezYXyaP67G5"
   },
   "source": [
    "### Balancing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2soYNev367G7",
    "outputId": "3e6e86c4-a431-4131-e734-028664b73fcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(773, 7411)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.tsv.zip', sep='\\t')\n",
    "test_df = pd.read_csv('test.tsv.zip', sep='\\t')\n",
    "valid_df = pd.read_csv('valid.tsv', sep='\\t')\n",
    "\n",
    "train_positive_class_df = train_df[train_df['label'] == 1]\n",
    "train_negative_class_df = train_df[train_df['label'] == 0]\n",
    "\n",
    "len(train_positive_class_df), len(train_negative_class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJ5mF25f5-Aq"
   },
   "outputs": [],
   "source": [
    "num_positive_examples = len(train_positive_class_df)\n",
    "\n",
    "# For training set, we take the same amount of positive and negative examples\n",
    "train_negative_class_df = train_negative_class_df.sample(num_positive_examples)\n",
    "# Concatenating positive and negative examples and shuffling the training set\n",
    "train_df = pd.concat((train_positive_class_df, train_negative_class_df)).sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRIy0Nzt67IZ"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "Preprocessing is adopted from:\n",
    "\n",
    "https://github.com/akutuzov/webvectors/blob/master/preprocessing/modular_processing/unify.py\n",
    "\n",
    "We unify letters to decrease the size of dictionary. We also unify and remove all punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8atWRqxj67Ia"
   },
   "outputs": [],
   "source": [
    "def list_replace(search, replacement, text):\n",
    "    '''\n",
    "    Replaces all symbols of text which are present\n",
    "    in the search string with the replacement string.\n",
    "    '''\n",
    "    search = [el for el in search if el in text]\n",
    "    for c in search:\n",
    "        text = text.replace(c, replacement)\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = list_replace(\n",
    "        '\\u00AB\\u00BB\\u2039\\u203A\\u201E\\u201A\\u201C\\u201F\\u2018\\u201B\\u201D\\u2019',\n",
    "         '\\u0022',\n",
    "          text\n",
    "    )\n",
    "\n",
    "    text = list_replace(\n",
    "        '\\u2012\\u2013\\u2014\\u2015\\u203E\\u0305\\u00AF',\n",
    "         '\\u2003\\u002D\\u002D\\u2003',\n",
    "          text\n",
    "    )\n",
    "\n",
    "    text = list_replace(\n",
    "        '\\u2010\\u2011',\n",
    "         '\\u002D',\n",
    "          text\n",
    "    )\n",
    "\n",
    "    text = list_replace(\n",
    "        '\\u2000\\u2001\\u2002\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u200B\\u202F\\u205F\\u2060\\u3000',\n",
    "        '\\u2002',\n",
    "        text\n",
    "    )\n",
    "\n",
    "    text = re.sub('\\u2003\\u2003', '\\u2003', text)\n",
    "    text = re.sub('\\t\\t', '\\t', text)\n",
    "\n",
    "    text = list_replace(\n",
    "        '\\u02CC\\u0307\\u0323\\u2022\\u2023\\u2043\\u204C\\u204D\\u2219\\u25E6\\u00B7\\u00D7\\u22C5\\u2219\\u2062',\n",
    "        '.',\n",
    "         text\n",
    "    )\n",
    "\n",
    "    text = list_replace('\\u2217', '\\u002A', text)\n",
    "\n",
    "    text = list_replace('…', '...', text)\n",
    "\n",
    "    text = list_replace('\\u00C4', 'A', text)\n",
    "    text = list_replace('\\u00E4', 'a', text)\n",
    "    text = list_replace('\\u00CB', 'E', text)\n",
    "    text = list_replace('\\u00EB', 'e', text)\n",
    "    text = list_replace('\\u1E26', 'H', text)\n",
    "    text = list_replace('\\u1E27', 'h', text)\n",
    "    text = list_replace('\\u00CF', 'I', text)\n",
    "    text = list_replace('\\u00EF', 'i', text)\n",
    "    text = list_replace('\\u00D6', 'O', text)\n",
    "    text = list_replace('\\u00F6', 'o', text)\n",
    "    text = list_replace('\\u00DC', 'U', text)\n",
    "    text = list_replace('\\u00FC', 'u', text)\n",
    "    text = list_replace('\\u0178', 'Y', text)\n",
    "    text = list_replace('\\u00FF', 'y', text)\n",
    "    text = list_replace('\\u00DF', 's', text)\n",
    "    text = list_replace('\\u1E9E', 'S', text)\n",
    "    # Removing punctuation\n",
    "    text = list_replace(',.[]{}()=+-−*&^%$#@!~;:§/\\|\\?\\'\\n', ' ', text)\n",
    "    # Replacing all numbers with masks\n",
    "    text = list_replace('0123456789', 'x', text)\n",
    "\n",
    "    currencies = list(\n",
    "            '\\u20BD\\u0024\\u00A3\\u20A4\\u20AC\\u20AA\\u2133\\u20BE\\u00A2\\u058F\\u0BF9\\u20BC\\u20A1\\u20A0\\u20B4\\u20A7\\u20B0\\u20BF\\u20A3\\u060B\\u0E3F\\u20A9\\u20B4\\u20B2\\u0192\\u20AB\\u00A5\\u20AD\\u20A1\\u20BA\\u20A6\\u20B1\\uFDFC\\u17DB\\u20B9\\u20A8\\u20B5\\u09F3\\u20B8\\u20AE\\u0192'\n",
    "    )\n",
    "\n",
    "    alphabet = list(\n",
    "        '\\t\\r абвгдеёзжийклмнопрстуфхцчшщьыъэюяАБВГДЕЁЗЖИЙКЛМНОПРСТУФХЦЧШЩЬЫЪЭЮЯabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ '\n",
    "    )\n",
    "\n",
    "    allowed = set(currencies + alphabet)\n",
    "\n",
    "    cleaned_text = [sym for sym in text if sym in allowed]\n",
    "    cleaned_text = ''.join(cleaned_text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7A4Z8xQ67If"
   },
   "outputs": [],
   "source": [
    "# Extracting tweet texts\n",
    "train_tweet_texts = train_df.tweet.values\n",
    "test_tweet_texts = test_df.tweet.values\n",
    "valid_tweet_texts = valid_df.tweet.values\n",
    "\n",
    "# Extracting tweet labels\n",
    "train_labels = train_df['label'].values\n",
    "valid_labels = valid_df['label'].values\n",
    "\n",
    "# Preprocessing training tweets\n",
    "cleaned_train_texts = []\n",
    "for tweet_text in train_tweet_texts:\n",
    "    cleaned_text = clean_text(tweet_text).lower()\n",
    "    split_cleaned_text = cleaned_text.split()\n",
    "    cleaned_train_texts.append(' '.join(split_cleaned_text))\n",
    "    \n",
    "# Preprocessing test tweets\n",
    "cleaned_test_texts = []\n",
    "for tweet_text in test_tweet_texts:\n",
    "    cleaned_text = clean_text(tweet_text)\n",
    "    cleaned_test_texts.append(' '.join(cleaned_text.split()))\n",
    "    \n",
    "# Preprocessing validation tweets\n",
    "cleaned_valid_texts = []\n",
    "for tweet_text in valid_tweet_texts:\n",
    "    cleaned_text = clean_text(tweet_text)\n",
    "    cleaned_valid_texts.append(' '.join(cleaned_text.split()))\n",
    "\n",
    "train_df['clean_text'] = cleaned_train_texts\n",
    "valid_df['clean_text'] = cleaned_valid_texts\n",
    "test_df['clean_text'] = cleaned_test_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR-LZpf6rIJr"
   },
   "source": [
    "### Model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCJpoamjsL0-"
   },
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'cimm-kzn/enrudr-bert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Noe485H_rL7Z"
   },
   "outputs": [],
   "source": [
    "class TwitterClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, use_kd=False):\n",
    "        super(TwitterClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "        self.use_kd = use_kd\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]     \n",
    "        if self.use_kd:\n",
    "            middle_hidden_state_cls = outputs[2][5][:, 0, :]\n",
    "            return self.out(self.drop(last_hidden_state_cls)), self.out(self.drop(middle_hidden_state_cls))\n",
    "        return self.out(self.drop(last_hidden_state_cls))\n",
    "\n",
    "class TwitterDataset(Dataset):\n",
    "    def __init__(self, ids, tweets, targets, tokenizer, max_len):\n",
    "        self.ids = ids\n",
    "        self.tweets = tweets\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweets)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        tweet = str(self.tweets[item])\n",
    "        target = self.targets[item]\n",
    "        id = self.ids[item]\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "        )\n",
    "        return {\n",
    "            'id': id,\n",
    "            'tweet_text': tweet,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_hzBWCjGKASQ",
    "outputId": "fce013ae-d01e-40a4-c43f-65e73d17b866"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n",
      "124\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "\n",
    "train_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_train_texts]\n",
    "valid_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_valid_texts]\n",
    "test_tokenized = [tokenizer.encode(x, add_special_tokens=True) for x in cleaned_test_texts]\n",
    "\n",
    "train_max_len = max(map(len, train_tokenized))\n",
    "valid_max_len = max(map(len, valid_tokenized))\n",
    "test_max_len = max(map(len, valid_tokenized))\n",
    "\n",
    "print(train_max_len)\n",
    "print(valid_max_len)\n",
    "print(test_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PriOOpje-ykn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def create_data_loader(df, tokenizer, batch_size, max_len):\n",
    "    if 'label' in df:\n",
    "        labels = df.label.values\n",
    "    else:\n",
    "        labels = [0] * len(df)\n",
    "    ds = TwitterDataset(\n",
    "        ids = df.tweet_id.values,\n",
    "        tweets= df.clean_text.values,\n",
    "        targets=labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_data_loader = create_data_loader(train_df, tokenizer, BATCH_SIZE, train_max_len)\n",
    "valid_data_loader = create_data_loader(valid_df, tokenizer, BATCH_SIZE, valid_max_len)\n",
    "test_data_loader = create_data_loader(test_df, tokenizer, BATCH_SIZE, test_max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNCGGRUiwp1L"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r5QTi21xDOwM",
    "outputId": "48268210-78b3-4145-b6af-f526552b2224"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cimm-kzn/enrudr-bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TwitterClassifier(n_classes, True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-q6EjhK1TVn",
    "outputId": "59226a0d-35ca-43b2-8e2d-cd719636fd6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yTirMAKbwn2e"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgnONPoHuscw"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_fn_kd(outputs, labels, teacher_outputs):\n",
    "    alpha = 0.3\n",
    "    T = 1\n",
    "    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
    "              F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "\n",
    "    return KD_loss\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in tqdm(data_loader, desc='TRAIN'):\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def train_epoch_kd(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in tqdm(data_loader, desc='TRAIN'):\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(device)\n",
    "\n",
    "        outputs_full, outputs_middle = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs_middle, dim=1)\n",
    "        loss_full = loss_fn(outputs_full, targets)\n",
    "        kd_loss = loss_fn_kd(outputs_middle, targets, outputs_full)\n",
    "        loss = 1e-1 * loss_full + kd_loss\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TOYVwIHcy1zx"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in tqdm(data_loader, desc='EVALUATION'):\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model_kd(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in tqdm(data_loader, desc='EVALUATION'):\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        targets = d['targets'].to(device)\n",
    "        outputs_full, outputs_middle = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs_middle, dim=1)\n",
    "        loss_full = loss_fn(outputs_full, targets)\n",
    "        kd_loss = loss_fn_kd(outputs_middle, targets, outputs_full)\n",
    "        loss = loss_full + kd_loss\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kakZPyMvzTTz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for epoch in range(1):\n",
    "#     print(f'Epoch {epoch + 1:2d}/{EPOCHS:2d}')\n",
    "#     print('-' * 10)\n",
    "\n",
    "#     train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_df))\n",
    "#     valid_acc, valid_loss = eval_model(model, valid_data_loader, loss_fn, device, len(valid_df))\n",
    "    \n",
    "#     print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n",
    "#     print(f'Valid loss {valid_loss:.4f} accuracy {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "faf1958673ce460390c3939c9deb7f90",
      "f0c5883f73f948b6bb1f98d703ff213c",
      "3f62c32ad7b44cac8a0ad0e3c6446f05",
      "8b9036322be74b598b3cfbf688d35525",
      "877acba33fd34e79b9abb991e3e6fe4d",
      "cf2aec082ce84a21bc974be00b820fb8",
      "35ab962151cb48548941e6b18c67fdca",
      "d8bdbbf169004b0da9e54a41f34e65ea",
      "cc992ece3d3c4e80bec7e1c178767201",
      "708477557b854410bb93a6a679a7c35a",
      "bd1baf22fb8d4e51bce1871933439210",
      "3fe7f38a74d64ad6a7bcc92eb6709cd3",
      "89c13eff0cb84e18b5f010fa359bad53",
      "c7085e3f36784d20887d4813b410a845",
      "7cf169453e6443cb9bffaa0ea5790915",
      "3c00031136bf4811818f908daf963198",
      "389dd6844416436eb5d92be3cf9f5984",
      "743f85669a5b4fbb8f7c0ba59b76b9c4",
      "3607e9cb56f44876921a1002e947f122",
      "23bbeadb6edc41cc88c344fd33b7518c",
      "dc3eb5e77c47445b950757d8923dd108",
      "f551fab81f574bef96bc5287ddb570dc"
     ]
    },
    "id": "FhN2EsSZEG5Y",
    "outputId": "a0c49ee3-7ed1-4c31-d562-91bc7861db24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/ 1\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf1958673ce460390c3939c9deb7f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe7f38a74d64ad6a7bcc92eb6709cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EVALUATION:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4779 accuracy 0.6740\n",
      "Valid loss 0.8758 accuracy 0.7416\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    print(f'Epoch {epoch + 1:2d}/{EPOCHS:2d}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch_kd(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(train_df))\n",
    "    valid_acc, valid_loss = eval_model_kd(model, valid_data_loader, loss_fn, device, len(valid_df))\n",
    "    \n",
    "    print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n",
    "    print(f'Valid loss {valid_loss:.4f} accuracy {valid_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "9c2040085d6f4166afd6b512f66069f6",
      "aa98507b57f14fd3968fa4f278932c96",
      "fa72fe9d21e94949b931e63ab90015a9",
      "06c594c73cd840999f7efe69c3d91bb6",
      "4b4f8fb448cf4d7dac3135a6c0c7f6ab",
      "4cdda45cf6e74460b427a81b9d727acf",
      "f07787eda8a047d1b5d858b47dcac8df",
      "740f9d346a4b4678badba5094bc420bf",
      "c3cf965af4a543b18bfca13cec6e02f9",
      "4757fcebffff4d6e8ae93c452fc2b457",
      "791bc2d64e18473ab21e12d66a967479"
     ]
    },
    "id": "fUWlACkIYrPn",
    "outputId": "5a607356-8a32-4dac-d2a8-98dbfb5f71cf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2040085d6f4166afd6b512f66069f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EVALUATION:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.7728, device='cuda:0', dtype=torch.float64), 0.8758427268928952)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model_kd(model, valid_data_loader, loss_fn, device, len(valid_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjHQj5saE5JJ"
   },
   "source": [
    "# Эксперимент 2\n",
    "\n",
    "Линейные слои, внутри которых учим самые влиятельные веса тоже быть сильными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPrunning(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = torch.nn.Parameter(torch.randn(out_features, in_features))\n",
    "        print(self.weight.shape)\n",
    "        self.bias = torch.nn.Parameter(torch.randn(out_features))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)\n",
    "        self.scale = 0.5\n",
    "       \n",
    "        \n",
    "    def forward(self, x, scale=None, return_output=False):\n",
    "        output_full = x @ self.weight.t() + self.bias\n",
    "        if return_output:\n",
    "            return output_full\n",
    "        if scale is not None:\n",
    "            mangitudes = (self.weight ** 2).sum(0)\n",
    "            threshhold = torch.kthvalue(mangitudes, int(len(mangitudes) * scale)).values.item()\n",
    "            strong_idxs = torch.zeros(len(mangitudes))\n",
    "            strong_idxs[torch.arange(len(mangitudes))[mangitudes > threshhold]] = 1\n",
    "            output = x @ (self.weight @ torch.diag(strong_idxs)).t() + self.bias\n",
    "            return output, output_full\n",
    "        else:\n",
    "            return output_full, output_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hidden_size=40):\n",
    "        super(Net, self).__init__()\n",
    "        # here you construct weights for layers\n",
    "        self.fc1 = LinearPrunning(784, hidden_size)\n",
    "        self.fc2 = LinearPrunning(hidden_size, hidden_size)\n",
    "        self.fc3 = LinearPrunning(hidden_size, 10)\n",
    "        \n",
    "    def forward(self, x, use_full=True, scale_all=None):\n",
    "        if use_full and scale_all is None:\n",
    "            x = F.relu(self.fc1(x, return_output=True))\n",
    "            x = F.relu(self.fc2(x, return_output=True))\n",
    "            x = self.fc3(x, return_output=True)\n",
    "            # check log_softmax signature\n",
    "            return F.log_softmax(x, dim=-1)\n",
    "        else:\n",
    "            if scale_all is None:\n",
    "                l_idx = random.randint(1, 2)\n",
    "                scales = [0.5] * 3\n",
    "                x, x_full = self.fc1(x, scales[0])\n",
    "                if scales[0] is not None:\n",
    "                    prom_fake = x\n",
    "                    prom_true = x_full.detach()\n",
    "                x = F.relu(x)\n",
    "                x, x_full = self.fc2(x, scales[1])\n",
    "                if scales[1] is not None:\n",
    "                    prom_fake = x\n",
    "                    prom_true = x_full.detach()\n",
    "                x = F.relu(x)\n",
    "                x, x_full = self.fc3(x, scales[2])\n",
    "                if scales[2] is not None:\n",
    "                    prom_fake = x\n",
    "                    prom_true = x_full.detach()\n",
    "                return F.log_softmax(x, dim=-1), prom_fake, prom_true\n",
    "            else:\n",
    "                x = F.relu(self.fc1(x, return_output=True))\n",
    "                x = F.relu(self.fc2(x, 0.5)[0])\n",
    "                x, _ = self.fc3(x, 0.5)\n",
    "                # check log_softmax signature\n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_fn_kd(outputs, labels, teacher_outputs, params):\n",
    "    \"\"\"\n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! See Issue #2\n",
    "    \"\"\"\n",
    "    alpha = params['alpha']\n",
    "    T = params['temperature']\n",
    "    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),\n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \\\n",
    "              F.cross_entropy(outputs, labels) * (1. - alpha)\n",
    "\n",
    "    return KD_loss\n",
    "\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataloader):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for data, target in dataloader:\n",
    "        # data preparation\n",
    "        data = data.flatten(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        sub_output, prom_fake, prom_true = model(data, False)\n",
    "        # loss_2 = ((prom_fake - prom_true) ** 2).mean()\n",
    "\n",
    "        full_output = model(data, use_full=True)\n",
    "        kd_loss = loss_fn_kd(sub_output, target, full_output,{\"alpha\" : 0.95, \"temperature\" : 6})\n",
    "        teacher_loss = F.cross_entropy(full_output, target)\n",
    "        \n",
    "        \n",
    "        total_loss = kd_loss + 1e-2 * teacher_loss\n",
    "            # compute gradients\n",
    "        l1_lambda = 1e-5\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "        total_loss = total_loss + l1_lambda * l1_norm\n",
    "        total_loss.backward()\n",
    "        loss_log.append([teacher_loss, kd_loss, total_loss])\n",
    "        optimizer.step()\n",
    "    return loss_log\n",
    "\n",
    "\n",
    "\n",
    "def train_normal(model, optimizer, dataloader):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for data, target in dataloader:\n",
    "        # data preparation\n",
    "        data = data.flatten(1)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data, use_full=True)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        total_loss = loss\n",
    "            # compute gradients\n",
    "        l1_lambda = 1e-5\n",
    "        l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "\n",
    "        total_loss = total_loss + l1_lambda * l1_norm\n",
    "        total_loss.backward()\n",
    "        # make a step\n",
    "        optimizer.step()\n",
    "    return loss_log\n",
    "\n",
    "# TODO: написать функцию для валидации по X_val, y_val\n",
    "# # hint: optimizer не нужен\n",
    "# def test(model):\n",
    "#     loss_log = []\n",
    "#     model.eval()\n",
    "#     <your code>\n",
    "    \n",
    "#     return loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "validationset = datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
    "val_loader = DataLoader(validationset, batch_size=32, shuffle=True)\n",
    "\n",
    "# plt.figure(figsize=[6, 6])\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2, 2, i + 1)\n",
    "#     plt.title(\"Label: %i\" % y_train[i])\n",
    "#     plt.imshow(X_train[i].reshape([28, 28]), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = []\n",
    "val_log = []\n",
    "\n",
    "model = Net(10)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(60):\n",
    "    print(epoch)\n",
    "    train_loss = train(model, opt, train_loader)\n",
    "    train_log.extend(train_loss)\n",
    "    s_scale = 0\n",
    "    s_full = 0\n",
    "    c = 0\n",
    "    for x, y in val_loader:\n",
    "        x = x.flatten(1)\n",
    "        s_full +=(model(x).argmax(1) == y).sum()\n",
    "        s_scale +=(model(x, scale_all=True).argmax(1) == y).sum()\n",
    "        c += y.shape[0]\n",
    "    \n",
    "    print(\"FULL ACCURACY: \", s_full / c)\n",
    "    print(\"SCALED ACCURACY: \", s_scale / c)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "U57Hx7J0CgFq",
    "aezYXyaP67G5",
    "DR-LZpf6rIJr",
    "A11S0uwsp9jm",
    "Kms46cam67I_",
    "kC2UQzQDKE69"
   ],
   "name": "nis_exp_transformer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06c594c73cd840999f7efe69c3d91bb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3cf965af4a543b18bfca13cec6e02f9",
      "max": 108,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_740f9d346a4b4678badba5094bc420bf",
      "value": 108
     }
    },
    "23bbeadb6edc41cc88c344fd33b7518c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35ab962151cb48548941e6b18c67fdca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3607e9cb56f44876921a1002e947f122": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "389dd6844416436eb5d92be3cf9f5984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c00031136bf4811818f908daf963198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f551fab81f574bef96bc5287ddb570dc",
      "placeholder": "​",
      "style": "IPY_MODEL_dc3eb5e77c47445b950757d8923dd108",
      "value": " 108/108 [00:52&lt;00:00,  2.06it/s]"
     }
    },
    "3f62c32ad7b44cac8a0ad0e3c6446f05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35ab962151cb48548941e6b18c67fdca",
      "placeholder": "​",
      "style": "IPY_MODEL_cf2aec082ce84a21bc974be00b820fb8",
      "value": "TRAIN: 100%"
     }
    },
    "3fe7f38a74d64ad6a7bcc92eb6709cd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c7085e3f36784d20887d4813b410a845",
       "IPY_MODEL_7cf169453e6443cb9bffaa0ea5790915",
       "IPY_MODEL_3c00031136bf4811818f908daf963198"
      ],
      "layout": "IPY_MODEL_89c13eff0cb84e18b5f010fa359bad53"
     }
    },
    "4757fcebffff4d6e8ae93c452fc2b457": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b4f8fb448cf4d7dac3135a6c0c7f6ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_791bc2d64e18473ab21e12d66a967479",
      "placeholder": "​",
      "style": "IPY_MODEL_4757fcebffff4d6e8ae93c452fc2b457",
      "value": " 108/108 [00:52&lt;00:00,  2.04it/s]"
     }
    },
    "4cdda45cf6e74460b427a81b9d727acf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "708477557b854410bb93a6a679a7c35a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "740f9d346a4b4678badba5094bc420bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "743f85669a5b4fbb8f7c0ba59b76b9c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791bc2d64e18473ab21e12d66a967479": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf169453e6443cb9bffaa0ea5790915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23bbeadb6edc41cc88c344fd33b7518c",
      "max": 108,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3607e9cb56f44876921a1002e947f122",
      "value": 108
     }
    },
    "877acba33fd34e79b9abb991e3e6fe4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd1baf22fb8d4e51bce1871933439210",
      "placeholder": "​",
      "style": "IPY_MODEL_708477557b854410bb93a6a679a7c35a",
      "value": " 49/49 [00:59&lt;00:00,  1.01s/it]"
     }
    },
    "89c13eff0cb84e18b5f010fa359bad53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b9036322be74b598b3cfbf688d35525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc992ece3d3c4e80bec7e1c178767201",
      "max": 49,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d8bdbbf169004b0da9e54a41f34e65ea",
      "value": 49
     }
    },
    "9c2040085d6f4166afd6b512f66069f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa72fe9d21e94949b931e63ab90015a9",
       "IPY_MODEL_06c594c73cd840999f7efe69c3d91bb6",
       "IPY_MODEL_4b4f8fb448cf4d7dac3135a6c0c7f6ab"
      ],
      "layout": "IPY_MODEL_aa98507b57f14fd3968fa4f278932c96"
     }
    },
    "aa98507b57f14fd3968fa4f278932c96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd1baf22fb8d4e51bce1871933439210": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3cf965af4a543b18bfca13cec6e02f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7085e3f36784d20887d4813b410a845": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_743f85669a5b4fbb8f7c0ba59b76b9c4",
      "placeholder": "​",
      "style": "IPY_MODEL_389dd6844416436eb5d92be3cf9f5984",
      "value": "EVALUATION: 100%"
     }
    },
    "cc992ece3d3c4e80bec7e1c178767201": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf2aec082ce84a21bc974be00b820fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8bdbbf169004b0da9e54a41f34e65ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dc3eb5e77c47445b950757d8923dd108": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f07787eda8a047d1b5d858b47dcac8df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c5883f73f948b6bb1f98d703ff213c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f551fab81f574bef96bc5287ddb570dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa72fe9d21e94949b931e63ab90015a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f07787eda8a047d1b5d858b47dcac8df",
      "placeholder": "​",
      "style": "IPY_MODEL_4cdda45cf6e74460b427a81b9d727acf",
      "value": "EVALUATION: 100%"
     }
    },
    "faf1958673ce460390c3939c9deb7f90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f62c32ad7b44cac8a0ad0e3c6446f05",
       "IPY_MODEL_8b9036322be74b598b3cfbf688d35525",
       "IPY_MODEL_877acba33fd34e79b9abb991e3e6fe4d"
      ],
      "layout": "IPY_MODEL_f0c5883f73f948b6bb1f98d703ff213c"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
