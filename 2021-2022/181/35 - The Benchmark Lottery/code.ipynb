{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55e574d-ba8c-42db-ae21-f3aa5afe8ba4",
   "metadata": {},
   "source": [
    "Источники вдохновения:\n",
    "\n",
    "https://arxiv.org/abs/2109.08203 - Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision\n",
    "\n",
    "https://arxiv.org/abs/2107.07002 - The benchmark lottery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2480c-04e5-4269-991b-48b1fe4d0948",
   "metadata": {},
   "source": [
    "### CIFAR10 + минимодель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50896b9-d71a-4d64-beeb-1afdb9187570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a3f1801-5ad4-4fb9-96e6-90128001e1ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5876d3105e6a4ee8b129b7fdd3cfa369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6488]\n",
      "[0.6488, 0.6581]\n",
      "[0.6488, 0.6581, 0.6566]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561, 0.6447]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561, 0.6447, 0.6519]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561, 0.6447, 0.6519, 0.6479]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561, 0.6447, 0.6519, 0.6479, 0.6469]\n",
      "[0.6488, 0.6581, 0.6566, 0.6479, 0.6526, 0.6284, 0.6455, 0.6651, 0.6494, 0.6556, 0.6685, 0.6485, 0.6506, 0.6461, 0.648, 0.6311, 0.644, 0.6417, 0.6508, 0.6613, 0.6514, 0.6458, 0.6463, 0.6592, 0.6561, 0.6447, 0.6519, 0.6479, 0.6469, 0.6435]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "best_tests = []\n",
    "for seed in tqdm(range(30)):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    net = Net()\n",
    "    net.to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(net.parameters(), lr=0.0004)\n",
    "    best_test = 0\n",
    "    for epoch in range(30):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to('cuda')\n",
    "            labels = labels.to('cuda')\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                images = images.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                # calculate outputs by running images through the network\n",
    "                outputs = net(images)\n",
    "                # the class with the highest energy is what we choose as prediction\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = correct / total\n",
    "        best_test = max(test_accuracy, best_test)\n",
    "    best_tests.append(best_test)\n",
    "    print(best_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dca0d9a2-814d-4c21-a3fc-18160cc1179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tests = np.array(best_tests)\n",
    "with open('cifar.npy', 'wb') as f:\n",
    "    np.save(f, best_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67383109-682e-4395-9121-f3455ddb0ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best test accuracy with different seed')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(best_tests, np.zeros(best_tests.shape))\n",
    "plt.grid()\n",
    "plt.title(\"Best test accuracy with different seed\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19015ca8-e392-4245-834a-8ce58db608cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040100000000000025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tests.max() - best_tests.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd94b7a3-2ead-4a3d-b2d9-d15ce36a33f4",
   "metadata": {},
   "source": [
    "### IMDB + roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71769d9-c561-420d-9a4b-b84d12d11f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_OFFLINE'] = '1'\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32dec56-f6a1-47f7-a1d5-2a9191118317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/vapavlov_4/.cache/huggingface/modules/datasets_modules/datasets/imdb/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1 (last modified on Thu Mar 10 19:11:10 2022) since it couldn't be found locally at imdb.\n",
      "Reusing dataset imdb (.cache/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f710981070741ac9951142d9c4337d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb = load_dataset(\"imdb\", cache_dir='.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07dfd72b-d10d-4c1f-90c0-469b155ea33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir='.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a759744-97c7-4ad7-8788-edf919408db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=30)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ad7a5e-bc6a-496d-9260-ae738cfc793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at .cache/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-f90a92089c434c2c.arrow\n",
      "Loading cached processed dataset at .cache/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-e5cec8ad29fe6fb0.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00ec0195b7a4085ac752a5c3efb6580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at .cache/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-52d17402e7f20baf.arrow\n",
      "Loading cached shuffled indices for dataset at .cache/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-4b63a88884914cac.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_imdb = imdb.map(preprocess_function, batched=True, remove_columns=[\"text\"]).shuffle(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba625c36-b39a-47df-b8be-06e3fbc3a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7264327-4fa8-47c4-8444-f37e8a41040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tokenized_imdb[\"test\"].select(range(15000))\n",
    "test = tokenized_imdb[\"test\"].select(range(15000, 25000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e797eb30-c92e-477a-a0d2-79d99ae354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ce5ca3-c93a-44e2-8cd4-bf311523d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c976329d-6b97-40ad-b35d-24d7317b7243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/vapavlov_4/.cache/huggingface/modules/datasets_modules/metrics/accuracy/bbddc2dafac9b46b0aeeb39c145af710c55e03b223eae89dfe86388f40d9d157 (last modified on Tue Feb 15 18:06:21 2022) since it couldn't be found locally at accuracy, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
    "        \n",
    "    loss = loss_fct(torch.tensor(logits), torch.tensor(labels))\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = metric.compute(predictions=predictions, references=labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef314c7-0863-4c82-a9b1-38026ad54f49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572300</td>\n",
       "      <td>0.480487</td>\n",
       "      <td>0.755520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498400</td>\n",
       "      <td>0.466891</td>\n",
       "      <td>0.759640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.459577</td>\n",
       "      <td>0.761680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.454708</td>\n",
       "      <td>0.766640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.464700</td>\n",
       "      <td>0.452247</td>\n",
       "      <td>0.769760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.460300</td>\n",
       "      <td>0.767320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457100</td>\n",
       "      <td>0.447628</td>\n",
       "      <td>0.773080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454600</td>\n",
       "      <td>0.448416</td>\n",
       "      <td>0.773760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449600</td>\n",
       "      <td>0.452319</td>\n",
       "      <td>0.770960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.450519</td>\n",
       "      <td>0.770880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-5474 (score: 0.44762831926345825).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.570900</td>\n",
       "      <td>0.479559</td>\n",
       "      <td>0.756360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.468190</td>\n",
       "      <td>0.758320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.479800</td>\n",
       "      <td>0.456039</td>\n",
       "      <td>0.766600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472100</td>\n",
       "      <td>0.462418</td>\n",
       "      <td>0.762440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.450038</td>\n",
       "      <td>0.772080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461000</td>\n",
       "      <td>0.459562</td>\n",
       "      <td>0.768560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.447391</td>\n",
       "      <td>0.772960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.452408</td>\n",
       "      <td>0.771560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.451400</td>\n",
       "      <td>0.449408</td>\n",
       "      <td>0.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.448934</td>\n",
       "      <td>0.774120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-5474 (score: 0.4473911225795746).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.488288</td>\n",
       "      <td>0.748560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498100</td>\n",
       "      <td>0.469118</td>\n",
       "      <td>0.758880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481100</td>\n",
       "      <td>0.465232</td>\n",
       "      <td>0.762840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.457403</td>\n",
       "      <td>0.769760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.463516</td>\n",
       "      <td>0.763920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462100</td>\n",
       "      <td>0.451023</td>\n",
       "      <td>0.770680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458500</td>\n",
       "      <td>0.454463</td>\n",
       "      <td>0.770240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.449686</td>\n",
       "      <td>0.773280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0.450436</td>\n",
       "      <td>0.774160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.449102</td>\n",
       "      <td>0.773080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.4491022229194641).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.564600</td>\n",
       "      <td>0.493553</td>\n",
       "      <td>0.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497300</td>\n",
       "      <td>0.479933</td>\n",
       "      <td>0.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.460891</td>\n",
       "      <td>0.766280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.456287</td>\n",
       "      <td>0.767120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466800</td>\n",
       "      <td>0.453683</td>\n",
       "      <td>0.769240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.460900</td>\n",
       "      <td>0.450280</td>\n",
       "      <td>0.772720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457200</td>\n",
       "      <td>0.452798</td>\n",
       "      <td>0.772440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.449626</td>\n",
       "      <td>0.772920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.447393</td>\n",
       "      <td>0.774280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.448800</td>\n",
       "      <td>0.449147</td>\n",
       "      <td>0.773440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7038 (score: 0.44739311933517456).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>0.485702</td>\n",
       "      <td>0.754440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.499200</td>\n",
       "      <td>0.472197</td>\n",
       "      <td>0.759720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.464714</td>\n",
       "      <td>0.763960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.463504</td>\n",
       "      <td>0.764440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465200</td>\n",
       "      <td>0.453527</td>\n",
       "      <td>0.768440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.453572</td>\n",
       "      <td>0.771840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.456275</td>\n",
       "      <td>0.768040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.450813</td>\n",
       "      <td>0.774560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.451335</td>\n",
       "      <td>0.773120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.449700</td>\n",
       "      <td>0.450515</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.45051461458206177).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>0.481081</td>\n",
       "      <td>0.755760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496800</td>\n",
       "      <td>0.472593</td>\n",
       "      <td>0.759960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483000</td>\n",
       "      <td>0.459189</td>\n",
       "      <td>0.766160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.462257</td>\n",
       "      <td>0.762240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.464200</td>\n",
       "      <td>0.454717</td>\n",
       "      <td>0.767960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>0.769040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457500</td>\n",
       "      <td>0.447643</td>\n",
       "      <td>0.774240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.448820</td>\n",
       "      <td>0.771120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.453816</td>\n",
       "      <td>0.769400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.448400</td>\n",
       "      <td>0.448266</td>\n",
       "      <td>0.775560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-5474 (score: 0.4476425349712372).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567400</td>\n",
       "      <td>0.485038</td>\n",
       "      <td>0.751680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.473949</td>\n",
       "      <td>0.760880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.466381</td>\n",
       "      <td>0.767120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473700</td>\n",
       "      <td>0.455573</td>\n",
       "      <td>0.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.457030</td>\n",
       "      <td>0.769360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462200</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>0.770600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.761080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454100</td>\n",
       "      <td>0.450384</td>\n",
       "      <td>0.775480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.449986</td>\n",
       "      <td>0.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.450360</td>\n",
       "      <td>0.774080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7038 (score: 0.44998589158058167).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.566300</td>\n",
       "      <td>0.484956</td>\n",
       "      <td>0.755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.466376</td>\n",
       "      <td>0.759880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482700</td>\n",
       "      <td>0.458964</td>\n",
       "      <td>0.765600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.471700</td>\n",
       "      <td>0.452845</td>\n",
       "      <td>0.770120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466600</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.770200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.449453</td>\n",
       "      <td>0.774160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.452401</td>\n",
       "      <td>0.772760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.452800</td>\n",
       "      <td>0.448922</td>\n",
       "      <td>0.774560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449100</td>\n",
       "      <td>0.449893</td>\n",
       "      <td>0.773680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.448652</td>\n",
       "      <td>0.774320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.4486517310142517).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.570600</td>\n",
       "      <td>0.481046</td>\n",
       "      <td>0.756440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.469172</td>\n",
       "      <td>0.762040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.462397</td>\n",
       "      <td>0.766080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474700</td>\n",
       "      <td>0.453583</td>\n",
       "      <td>0.769760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465600</td>\n",
       "      <td>0.452998</td>\n",
       "      <td>0.771600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.460500</td>\n",
       "      <td>0.448524</td>\n",
       "      <td>0.772800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.449796</td>\n",
       "      <td>0.772760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.453900</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0.770080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450900</td>\n",
       "      <td>0.450606</td>\n",
       "      <td>0.771840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.451303</td>\n",
       "      <td>0.771880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-4692 (score: 0.44852375984191895).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:22, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572600</td>\n",
       "      <td>0.486019</td>\n",
       "      <td>0.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>0.471024</td>\n",
       "      <td>0.756760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.485100</td>\n",
       "      <td>0.460217</td>\n",
       "      <td>0.762720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>0.458708</td>\n",
       "      <td>0.769280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.455424</td>\n",
       "      <td>0.770360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>0.451239</td>\n",
       "      <td>0.772120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.452119</td>\n",
       "      <td>0.770680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.453111</td>\n",
       "      <td>0.771280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.451100</td>\n",
       "      <td>0.450859</td>\n",
       "      <td>0.772120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.450689</td>\n",
       "      <td>0.774080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.4506888687610626).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.485724</td>\n",
       "      <td>0.754040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.477330</td>\n",
       "      <td>0.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482400</td>\n",
       "      <td>0.463284</td>\n",
       "      <td>0.759560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>0.454858</td>\n",
       "      <td>0.766280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>0.451272</td>\n",
       "      <td>0.770640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.459730</td>\n",
       "      <td>0.765280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457300</td>\n",
       "      <td>0.450740</td>\n",
       "      <td>0.773280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.452200</td>\n",
       "      <td>0.448212</td>\n",
       "      <td>0.773920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.449192</td>\n",
       "      <td>0.774360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.449875</td>\n",
       "      <td>0.772480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-6256 (score: 0.4482118487358093).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.491767</td>\n",
       "      <td>0.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470012</td>\n",
       "      <td>0.759800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482500</td>\n",
       "      <td>0.461239</td>\n",
       "      <td>0.764840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>0.458660</td>\n",
       "      <td>0.764760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.454446</td>\n",
       "      <td>0.771160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.459201</td>\n",
       "      <td>0.770680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.452340</td>\n",
       "      <td>0.771520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.453800</td>\n",
       "      <td>0.454659</td>\n",
       "      <td>0.770840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.449877</td>\n",
       "      <td>0.773120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.448582</td>\n",
       "      <td>0.773800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.44858235120773315).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.486188</td>\n",
       "      <td>0.754240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.465949</td>\n",
       "      <td>0.759960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480600</td>\n",
       "      <td>0.461223</td>\n",
       "      <td>0.768440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473100</td>\n",
       "      <td>0.452822</td>\n",
       "      <td>0.768480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.453175</td>\n",
       "      <td>0.771440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.460600</td>\n",
       "      <td>0.447488</td>\n",
       "      <td>0.773560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.457400</td>\n",
       "      <td>0.450132</td>\n",
       "      <td>0.771200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454500</td>\n",
       "      <td>0.448227</td>\n",
       "      <td>0.773760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.450197</td>\n",
       "      <td>0.773280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.448680</td>\n",
       "      <td>0.774040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-4692 (score: 0.44748789072036743).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:20, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.483726</td>\n",
       "      <td>0.752760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.481275</td>\n",
       "      <td>0.752640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482800</td>\n",
       "      <td>0.461709</td>\n",
       "      <td>0.763200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.460114</td>\n",
       "      <td>0.764080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.455183</td>\n",
       "      <td>0.769280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.455095</td>\n",
       "      <td>0.771360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.452408</td>\n",
       "      <td>0.772680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.451323</td>\n",
       "      <td>0.772560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.450375</td>\n",
       "      <td>0.773120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.449794</td>\n",
       "      <td>0.773040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7820 (score: 0.44979366660118103).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.484351</td>\n",
       "      <td>0.753960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498700</td>\n",
       "      <td>0.470047</td>\n",
       "      <td>0.759360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483300</td>\n",
       "      <td>0.472162</td>\n",
       "      <td>0.759320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.455640</td>\n",
       "      <td>0.768600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467700</td>\n",
       "      <td>0.452779</td>\n",
       "      <td>0.770760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461200</td>\n",
       "      <td>0.452038</td>\n",
       "      <td>0.769400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.455400</td>\n",
       "      <td>0.448575</td>\n",
       "      <td>0.773040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.454200</td>\n",
       "      <td>0.449766</td>\n",
       "      <td>0.772920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.773760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.449572</td>\n",
       "      <td>0.773400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-7038 (score: 0.44849976897239685).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7820/7820 07:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.568700</td>\n",
       "      <td>0.485242</td>\n",
       "      <td>0.755360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497600</td>\n",
       "      <td>0.469016</td>\n",
       "      <td>0.761520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>0.461036</td>\n",
       "      <td>0.763240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.475100</td>\n",
       "      <td>0.453970</td>\n",
       "      <td>0.767240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467800</td>\n",
       "      <td>0.451080</td>\n",
       "      <td>0.769000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>0.772080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.447575</td>\n",
       "      <td>0.772520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.449450</td>\n",
       "      <td>0.772960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.452235</td>\n",
       "      <td>0.771720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.450228</td>\n",
       "      <td>0.773640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-5474\n",
      "Configuration saved in ./research_imdb/checkpoint-5474/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-5474/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-5474/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-5474/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3910] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-6256\n",
      "Configuration saved in ./research_imdb/checkpoint-6256/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-6256/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-6256/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-6256/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-4692] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7038\n",
      "Configuration saved in ./research_imdb/checkpoint-7038/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7038/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7038/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7038/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-6256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-7820\n",
      "Configuration saved in ./research_imdb/checkpoint-7820/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-7820/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-7820/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-7820/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7038] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./research_imdb/checkpoint-5474 (score: 0.4475747346878052).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Offline mode: forcing local_files_only=True\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at .cache/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Offline mode: forcing local_files_only=True\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at .cache/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/vapavlov_4/.conda/envs/vapavlov_4/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 25000\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5426' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5426/7820 04:47 < 02:06, 18.85 it/s, Epoch 6.94/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.572000</td>\n",
       "      <td>0.483534</td>\n",
       "      <td>0.754120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.466179</td>\n",
       "      <td>0.761400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.465613</td>\n",
       "      <td>0.760240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.474500</td>\n",
       "      <td>0.455252</td>\n",
       "      <td>0.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.467900</td>\n",
       "      <td>0.457889</td>\n",
       "      <td>0.765600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>0.452248</td>\n",
       "      <td>0.770040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-782\n",
      "Configuration saved in ./research_imdb/checkpoint-782/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-782/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-782/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-782/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-5474] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-1564\n",
      "Configuration saved in ./research_imdb/checkpoint-1564/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-1564/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-1564/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-1564/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-7820] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-2346\n",
      "Configuration saved in ./research_imdb/checkpoint-2346/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-2346/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-2346/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-2346/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-782] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3128\n",
      "Configuration saved in ./research_imdb/checkpoint-3128/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3128/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3128/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3128/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-1564] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-3910\n",
      "Configuration saved in ./research_imdb/checkpoint-3910/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-3910/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-3910/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-3910/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-2346] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./research_imdb/checkpoint-4692\n",
      "Configuration saved in ./research_imdb/checkpoint-4692/config.json\n",
      "Model weights saved in ./research_imdb/checkpoint-4692/pytorch_model.bin\n",
      "tokenizer config file saved in ./research_imdb/checkpoint-4692/tokenizer_config.json\n",
      "Special tokens file saved in ./research_imdb/checkpoint-4692/special_tokens_map.json\n",
      "Deleting older checkpoint [research_imdb/checkpoint-3128] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, AutoConfig, TrainerCallback\n",
    "\n",
    "class BestAccuracyCallback(TrainerCallback):\n",
    "    \"A callback that prints a message at the beginning of training\"\n",
    "    def __init__(self):\n",
    "        self.val_accuracies = []\n",
    "    def on_evaluate(self, args, state, control, metrics, **kwargs):\n",
    "        self.val_accuracies.append(metrics['eval_accuracy'])\n",
    "\n",
    "test_accuracies = []\n",
    "val_accuracies = []\n",
    "for seed in range(20):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, cache_dir='.cache')\n",
    "    for name, param in model.named_parameters():\n",
    "        if not name.startswith(\"classifier\") and not '11' in name: # choose whatever you like here\n",
    "            param.requires_grad = False\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./research_imdb\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        save_strategy='epoch',\n",
    "        num_train_epochs=10,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        seed=seed,\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,  # strength of weight decay\n",
    "        max_grad_norm=1.0\n",
    "    )\n",
    "    callback = BestAccuracyCallback()\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_imdb[\"train\"],\n",
    "        eval_dataset=tokenized_imdb[\"test\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[callback],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    prediction = trainer.predict(test)\n",
    "    test_accuracies.append(prediction.metrics['test_accuracy'])\n",
    "    val_accuracies.extend(callback.val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1477913a-9913-43da-a42f-ef7aad70690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_accuracies = np.array(test_accuracies)\n",
    "val_accuracies = np.array(val_accuracies)\n",
    "with open('test.npy', 'wb') as f:\n",
    "    np.save(f, test_accuracies)\n",
    "with open('val.npy', 'wb') as f:\n",
    "    np.save(f, val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc2d131-59ce-4ad9-8ab1-4ecb1d78769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7029681c-901e-4f47-8b12-3580633f0a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test accuracy with different seed')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_accuracies, np.zeros(test_accuracies.shape))\n",
    "plt.grid()\n",
    "plt.title(\"Test accuracy with different seed\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0155ee46-a82c-47c7-87e3-13604a4fcaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031999999999999806"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracies.max() - test_accuracies.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0815c69-0f97-4ee9-a7c9-f7f561eb2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "val_accuracies = np.load('val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66e3c47c-5a9c-42de-be49-bda8c2d8e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vals = val_accuracies.reshape((20, 10)).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0926fa0-b033-45ff-8177-c9cbfdeac4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Best val accuracy with different seed')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(best_vals, np.zeros(best_vals.shape))\n",
    "plt.grid()\n",
    "plt.title(\"Best val accuracy with different seed\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bbb8820-3c76-4b43-820f-1b7298c2029a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0027599999999999847"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_vals.max() - best_vals.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee284df1-6018-4edc-87f8-aa7f1380aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-vapavlov_4]",
   "language": "python",
   "name": "conda-env-.conda-vapavlov_4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
