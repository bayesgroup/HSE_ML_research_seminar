{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Img2Img.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZCqbVvjY2my"
      },
      "source": [
        "#Используемые данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334bG2HkY6Mp"
      },
      "source": [
        "https://drive.google.com/drive/folders/1GrUAvxSE6y8WA0Lg5IE_mWwsf3LtHqmR?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMS6e5A_0ude"
      },
      "source": [
        "# Сохранение данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2cJyBvH0xq-"
      },
      "source": [
        "Обучение будет длится порядка 9-10 часов, поэтому лучше обезопасить себя от выходок колаба и сохранять все параллельно на диск"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDaHMGYuCfoq"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfnKCGkSZTgZ"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU1DC5HBZTK8",
        "outputId": "0a86e9d3-6187-45b9-a9a7-81f78e4a1a2c"
      },
      "source": [
        "cd /content/drive/MyDrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyU-VdZJ9tpL"
      },
      "source": [
        "#Загрузка библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZCFDVFG9nea",
        "outputId": "a1ea6563-8452-442d-f637-8308a08ebd25"
      },
      "source": [
        "!wget https://github.com/taesungp/contrastive-unpaired-translation/archive/87ab89cdca651f87742844016b0cfa49fa7bd3ee.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-29 13:54:11--  https://github.com/taesungp/contrastive-unpaired-translation/archive/87ab89cdca651f87742844016b0cfa49fa7bd3ee.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/taesungp/contrastive-unpaired-translation/zip/87ab89cdca651f87742844016b0cfa49fa7bd3ee [following]\n",
            "--2021-11-29 13:54:11--  https://codeload.github.com/taesungp/contrastive-unpaired-translation/zip/87ab89cdca651f87742844016b0cfa49fa7bd3ee\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘87ab89cdca651f87742844016b0cfa49fa7bd3ee.zip’\n",
            "\n",
            "87ab89cdca651f87742     [    <=>             ]  16.14M  20.4MB/s    in 0.8s    \n",
            "\n",
            "2021-11-29 13:54:13 (20.4 MB/s) - ‘87ab89cdca651f87742844016b0cfa49fa7bd3ee.zip’ saved [16925336]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G2zeNiv90us"
      },
      "source": [
        "!unzip -qq 87ab89cdca651f87742844016b0cfa49fa7bd3ee.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZYTyp_7949G",
        "outputId": "6496b1df-c531-4d44-8b19-91556b45a2e0"
      },
      "source": [
        "cd contrastive-unpaired-translation-87ab89cdca651f87742844016b0cfa49fa7bd3ee"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/contrastive-unpaired-translation-87ab89cdca651f87742844016b0cfa49fa7bd3ee\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO9OO6Kd96gS",
        "outputId": "c5248752-fd36-4b7c-9e28-0c7e0121cec8"
      },
      "source": [
        "pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.1+cu111)\n",
            "Collecting dominate>=2.4.0\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting visdom>=0.1.8.8\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (21.3)\n",
            "Collecting GPUtil>=1.4.0\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (22.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->-r requirements.txt (line 5)) (3.0.6)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom>=0.1.8.8->-r requirements.txt (line 4)) (3.0.4)\n",
            "Building wheels for collected packages: visdom, GPUtil, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=d77932adaaba1de704b9f06794c0b0a8fa9eb4fa841abcfb25f93b104001a8ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=8d23b5e32d726aba80569d854dff58fd4f0f4fdba22efdad240d8925d00bde47\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5710 sha256=785cc140c05d19ab372e44c82951f5d478fec0c11e42370d5f28051bad0fe972\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom GPUtil torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom, GPUtil, dominate\n",
            "Successfully installed GPUtil-1.4.0 dominate-2.6.0 jsonpatch-1.32 jsonpointer-2.2 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cc3V2KAk0WBP"
      },
      "source": [
        "# Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGB1sD100ZE4"
      },
      "source": [
        "Для начала нужно добавить в папку datasets папку с изображениями для эксперимента. В ней должно также быть 2 папки - trainA (изображение, откуда переводим) и trainB - изображение, куда переводим"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljmthM78Cc2q"
      },
      "source": [
        "## Делаем из корги маламута"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKB6wMybBLqL"
      },
      "source": [
        "!python train.py --model sincut  --name dog_party --dataroot ./datasets/dog_party"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuU-DVNoC1IJ"
      },
      "source": [
        "!python test.py --model sincut --name dog_party --dataroot ./datasets/dog_party"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aatE8tccOs1z"
      },
      "source": [
        "## Делаем из абстракции свинку пеппу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSe1-rPqOwby"
      },
      "source": [
        "!python train.py --model sincut  --name peppa_pig --dataroot ./datasets/peppa_pig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83GTtZUSOwho"
      },
      "source": [
        "!python test.py --model sincut --name peppa_pig --dataroot ./datasets/peppa_pig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0lyGIEY1OVy"
      },
      "source": [
        "## Повышаем качество изображения "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJS3jeA31P8K"
      },
      "source": [
        "!python train.py --model sincut  --name quality --dataroot ./datasets/quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "736k0OYJ1bXn"
      },
      "source": [
        "!python test.py --model sincut --name quality --dataroot ./datasets/quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx2g7U8QFAD4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAcouq4t9SGk"
      },
      "source": [
        "# Подобные изображения для обученной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-TjamSs9biW"
      },
      "source": [
        "Увы, путь до изображения захардкоджен в модель, поэтому есть 2 пути \n",
        "\n",
        "1) поменять изображение в Трейн А на нужное\n",
        "2) в папке data в файле singleimage_dataset.py изменить строку 29 \n",
        "\n",
        "с\n",
        "\n",
        "self.dir_A = os.path.join(opt.dataroot, 'trainA')\n",
        "\n",
        "на \n",
        "\n",
        "self.dir_A = os.path.join(opt.dataroot, 'testA')\n",
        "\n",
        "и создать такую папку в соих датасетах для этого эксперимента с нужным изображением"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mEE4v3o-m28"
      },
      "source": [
        "дальше - просто запускаем test.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QasP-Lrp9XpG"
      },
      "source": [
        "!python test.py --model sincut --name dog_party --dataroot ./datasets/dog_party"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN1mf3pTwwTU"
      },
      "source": [
        "# Эксперимент 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ONkMp74-yq"
      },
      "source": [
        "from packaging import version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTm7d4_o4-vg"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a221xxr0x7Ch"
      },
      "source": [
        "#нужно редактировать файл stylegan_networks.py в models\n",
        "\n",
        "#class StyleGAN2Generator -> forward\n",
        " def forward(self, input, layers=[], encode_only=False):\n",
        "        feat, feats = self.encoder(input, [1], True) # 1 - индекс первого блока резнета\n",
        "        # print(feats)\n",
        "        if encode_only:\n",
        "            return feats\n",
        "        else:\n",
        "            fake = self.decoder(feat)\n",
        "            return fake, feats\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDwG8LLi4-4E"
      },
      "source": [
        "#нужно редактировать файл cut_model.py в models\n",
        "\n",
        "\n",
        "#class CUTModel -> \n",
        "\n",
        "#def __init__\n",
        "\n",
        "#добавить 'feats_B' в self.visual_names, чтобы потом график построился\n",
        "\n",
        "\n",
        "#def forward модифицировать для возможности приема вектора признаков\n",
        "\n",
        " def forward(self):\n",
        "        \"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"\n",
        "        self.real = torch.cat((self.real_A, self.real_B), dim=0) if self.opt.nce_idt and self.opt.isTrain else self.real_A\n",
        "        if self.opt.flip_equivariance:\n",
        "            self.flipped_for_equivariance = self.opt.isTrain and (np.random.random() < 0.5)\n",
        "            if self.flipped_for_equivariance:\n",
        "                self.real = torch.flip(self.real, [3])\n",
        "\n",
        "        self.fake, self.feats = self.netG(self.real) #!\n",
        "\n",
        "        self.fake_B = self.fake[:self.real_A.size(0)]\n",
        "        self.feats_B = self.feats[0][:self.real_A.size(0)] #!\n",
        "\n",
        "        if self.opt.nce_idt:\n",
        "            self.idt_B = self.fake[self.real_A.size(0):]\n",
        "        \n",
        "        \n",
        "        self.fake_a, self.feats_a = self.netG(self.real_B)\n",
        "        self.feats_A = self.feats_a[0][:self.real_A.size(0)]\n",
        "\n",
        "## далее извлекаем вектора признаков всех патчей вхрдных данных\n",
        "        \n",
        "        base_ind_i = 50\n",
        "        base_ind_j = 800\n",
        "        \n",
        "        vector_base = self.feats_B[:,:,base_ind_i,base_ind_j].view(-1, 1)\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        result = torch.zeros((1, 3, self.feats_A.size(2), self.feats_A.size(3)))\n",
        "        \n",
        "        \n",
        "        for i in range(self.feats_A.size(2)):\n",
        "          if i % 25 == 0:\n",
        "            print(i)\n",
        "          for j in range(self.feats_A.size(3)):\n",
        "            vector_local = self.feats_A[:,:, i, j].view(-1, 1)\n",
        "            if i == 0 and j == 0:\n",
        "              print(torch.exp(torch.sum(vector_base * vector_local)/0.07))\n",
        "            result[0][0][i][j] = 1 - torch.exp(torch.sum(vector_base * vector_local)/0.07)\n",
        "            result[0][1][i][j] = result[0][0][i][j]\n",
        "            result[0][2][i][j] = result[0][0][i][j]\n",
        "        print(result)\n",
        "\n",
        "        base_ind_i = 100\n",
        "        base_ind_j = 1100\n",
        "\n",
        "        vector_base = self.feats_A[:,:,base_ind_i,base_ind_j].view(-1, 1)\n",
        "\n",
        "        result2 = torch.zeros((1, 3, self.feats_B.size(2), self.feats_B.size(3)))\n",
        "        \n",
        "        \n",
        "        for i in range(self.feats_B.size(2)):\n",
        "          if i % 25 == 0:\n",
        "            print(i)\n",
        "          for j in range(self.feats_Bsize(3)):\n",
        "            vector_local = self.feats_B[:,:, i, j].view(-1, 1)\n",
        "            if i == 0 and j == 0:\n",
        "              print(torch.exp(torch.sum(vector_base * vector_local)/0.07))\n",
        "            result2[0][0][i][j] = 1 - torch.exp(torch.sum(vector_base * vector_local)/0.07)\n",
        "            result2[0][1][i][j] = result2[0][0][i][j]\n",
        "            result2[0][2][i][j] = result2[0][0][i][j]\n",
        "\n",
        "\n",
        "\n",
        "        self.feats_B = result\n",
        "        self.feats_A = result2\n",
        "        print(self.feats_B.size())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa2c3QBfzUtB"
      },
      "source": [
        "теперь в папке results в  папке текущего эксперимента  должны появиться папки feats_B и feats_A с нужными изображениями\n",
        "\n",
        "NB -  если изображение слишком выского разрешения, то при прогоне его через генератор может закончится ОЗУ. советую сразу подбирать более маленькие размеры изображений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-4q2xCZ4-cM"
      },
      "source": [
        "!python test_test.py --model sincut --name dog_party --dataroot ./datasets/dog_party"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}